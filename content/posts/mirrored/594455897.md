+++
title = "有趣的CS - 微操日神仙"
author = "圆角骑士魔理沙"
date = 2022-12-26T19:03:00+08:00
tags = ["计算机科学", "雾雨魔法店"]
license = "CC BY-SA 4.0"
+++
今天想说一篇比较著名的paper：scalability! but at what cost?

这篇paper说的很简单：

以前，大家benchmark分布式框架(比如spark)比的是scalability，就是说看看1024个机器的spark比1个机器的spark快多少。但是，大家并没有比一个框架具体是多快！

比如说，你可以想象我们给spark加入一些负优化，导致spark在一切任务一切机器配置上都要双倍时间。这时候，scalability是一样的！甚至，我们给计算加入负优化，而不动数据传输，这时候scalability甚至会变好！

很明显，这是个发癫的metric。paper提出了另一个metric，COST，就是：我一台机器实现的代码，你们要开多少机器性能才追得上？

有的时候，是100台机器！

这paper的内容，其实到这就完结了。很明显，paper最重要的点是：谓，审稿人，别发电了，赶紧用一个正经点的metric。但很明显，改了metric以后这点就不需要再看了。

但我依旧认为这篇paper很有意义。

更具体的说，我们可以想象这样一个故事：

你是一个普通的Java程序员。有一天，你的程序跑得不够快，被PM要求加快速度。

这时候，你想：我应该上多线程！于是你看了看Java标准库的多线程怎么弄，怎么加锁，然后弄了弄，程序多线程以后快了点。

过了会，需求增长了，程序性能不够快了，但是你已经开了尽可能多的线程。这时候，你想：我用更多机器就好了！于是就弄上了spark，然后，请了些运维，弄了些机器连在一起。以后，当你计算力跟不上的时候，加机器就好了。

随着机器数量的增长，运维管得越来越麻烦，然后，你听说了一个叫做kubernetes的东东，可以自动跑你的计算，就不需要运维了。你弄了弄，花了不少时间弄各种配置。。。

但其实，是不是有另外一条路可以走？

在最初，当你程序出现性能问题的时候，你可以看看如何进行算法或者实现上面的优化。但是你用了多线程。这时候，你要面对race condition，死锁，bottleneck，contention等等正确性上面或者性能上面的问题。

然后，你遇上了这些性能问题，认为可以上分布式解决，这时候要给出数据传输的开销，还要思考集群的拓扑架构，然后机子出问题了还要retry。

处理这些问题太麻烦，于是你用上了spark根k8s之类的。

这时候你看看，本来你遇上了一个性能问题，你选择使用一种新方法解决这个性能问题。但是，这个新方法需要很多心思才能优化好。你没花这些心思，于是依旧有性能问题。你于是继续找更新的方法去‘解决’之，etc。。

这时候，最后的方案，真的比认真优化单核性能简单吗？
